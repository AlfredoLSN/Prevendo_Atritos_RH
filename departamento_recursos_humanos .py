# -*- coding: utf-8 -*-
"""Departamento Recursos Humanos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12nnkuHnNV8dWSrU5PzUUylqkpB930Nep

# Importação das bibliotecas e base de dados


*   Base de dados: https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset
*   Cálculo de salário: https://www.mom.gov.sg/employment-practices/salary/monthly-and-daily-salary e https://sprout.zendesk.com/hc/en-us/articles/360030922133-How-to-Calculate-for-the-Daily-Rate-from-Your-Monthly-Salary-
*   Stock: https://www.moneyunder30.com/employee-stock-options#:~:text=Typically%20they%20are%20granted%20to,a%20specific%20period%20of%20time.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

employee_df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Data Science - Empresas/Recursos Humanos/Human_Resources.csv")
employee_df.shape

employee_df.head()

employee_df.info()

employee_df.describe()

"""# Visualização dos Dados"""

employee_df['Attrition'] = employee_df['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)

employee_df['OverTime'] = employee_df['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)
employee_df['Over18'] = employee_df['Over18'].apply(lambda x: 1 if x == 'Yes' else 0)

employee_df.head()

sns.heatmap(employee_df.isnull(), cbar = False);

employee_df.hist(bins = 30, figsize=(20,20), color = 'r');

employee_df.drop(['EmployeeCount', "StandardHours", "Over18", "EmployeeNumber"], axis = 1, inplace = True)

employee_df.shape

left_df = employee_df[employee_df["Attrition"] == 1]
stayed_df = employee_df[employee_df["Attrition"] == 0]

print("Total = ", len(employee_df))
print("Número de funcionarios que sairam da empresa = ", len(left_df))
print("Porcentagem de funcionarios que sairam da empresa = ", (len(left_df) / len(employee_df)) * 100)
print("Número de funcionarios que sairam da empresa = ", len(stayed_df))
print("Porcentagem de funcionarios que sairam da empresa = ", (len(stayed_df) / len(employee_df)) * 100)

left_df.describe()

stayed_df.describe()

correlations = employee_df.corr()
f, ax = plt.subplots(figsize = (20,20))
sns.heatmap(correlations, annot=True);

plt.figure(figsize=[25,12])
sns.countplot(x = 'Age', hue = "Attrition", data=employee_df)

plt.figure(figsize=[20,20])
plt.subplot(411)
sns.countplot(x = "JobRole", hue = "Attrition", data = employee_df)
plt.subplot(412)
sns.countplot(x = "MaritalStatus", hue = "Attrition", data = employee_df)
plt.subplot(413)
sns.countplot(x = "JobInvolvement", hue = "Attrition", data = employee_df)
plt.subplot(414)
sns.countplot(x = "JobLevel", hue = "Attrition", data = employee_df)

# KDE (Kernel Density Estimate)
plt.figure(figsize = [12,7])
sns.kdeplot(left_df["DistanceFromHome"], label = "Funcionarios que sairam", color = "r", fill = True);
sns.kdeplot(stayed_df["DistanceFromHome"], label = "Funcionarios que ficaram", color = "b", fill = True);

plt.figure(figsize = [12,7])
sns.kdeplot(left_df["TotalWorkingYears"], label = "Funcionarios que sairam", color = "r", fill = True);
sns.kdeplot(stayed_df["TotalWorkingYears"], label = "Funcionarios que ficaram", color = "b", fill = True);

plt.figure(figsize = [15,10])
sns.boxplot(x = "MonthlyIncome", y = "Gender", data=employee_df);

plt.figure(figsize =[15,10])
sns.boxplot(x = "MonthlyIncome", y = "JobRole", data=employee_df);

"""# Pré-processamento e bases de treinamento/teste

"""

employee_df.head()

X_cat = employee_df[["BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus"]]
X_cat

from sklearn.preprocessing import OneHotEncoder
onehotencoder = OneHotEncoder()
X_cat = onehotencoder.fit_transform(X_cat).toarray()

X_cat.shape

type(X_cat)

X_cat = pd.DataFrame(X_cat)
type(X_cat)

X_cat

X_numerical = employee_df[['Age', 'DailyRate', 'DistanceFromHome',	'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement',	'JobLevel',	'JobSatisfaction',	'MonthlyIncome',	'MonthlyRate',	'NumCompaniesWorked',	'OverTime',	'PercentSalaryHike', 'PerformanceRating',	'RelationshipSatisfaction',	'StockOptionLevel',	'TotalWorkingYears'	,'TrainingTimesLastYear'	, 'WorkLifeBalance',	'YearsAtCompany'	,'YearsInCurrentRole', 'YearsSinceLastPromotion',	'YearsWithCurrManager']]
X_numerical

X_all = pd.concat([X_cat, X_numerical], axis = 1)
X_all

from sklearn.preprocessing import MinMaxScaler
X_all.columns = X_all.columns.astype(str)
scaler = MinMaxScaler()
X = scaler.fit_transform(X_all)

X

y = employee_df["Attrition"]
y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)

X_train.shape, y_train

X_test.shape, y_test

"""# Regressão logística"""

from sklearn.linear_model import LogisticRegression

logistic = LogisticRegression()
logistic.fit(X_train, y_train)

y_pred = logistic.predict(X_test)
y_pred

y_test

from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_pred)

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)
cm

sns.heatmap(cm, annot=True)

from sklearn.metrics import precision_score, recall_score, f1_score, classification_report

precision_score(y_test, y_pred)

recall_score(y_test, y_pred)

f1_score(y_test, y_pred, average="macro")

print(classification_report(y_test, y_pred))

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier

forest = RandomForestClassifier()
forest.fit(X_train, y_train)

y_pred = forest.predict(X_test)
y_pred

accuracy_score(y_test, y_pred)

cm = confusion_matrix(y_pred, y_test)
cm

sns.heatmap(cm, annot=True)

print(classification_report(y_test, y_pred))

"""# Redes Neurais"""

import tensorflow as tf

X_train.shape

#50 = Numero de entradas
#1 = Numero de saidas
(50 + 1) / 2

rede_neural = tf.keras.models.Sequential()
rede_neural.add(tf.keras.layers.Dense(units = 25, activation = "relu", input_shape=(50,)))
rede_neural.add(tf.keras.layers.Dense(units = 25, activation = "relu"))
rede_neural.add(tf.keras.layers.Dense(units = 25, activation = "relu"))
rede_neural.add(tf.keras.layers.Dense(units = 1, activation = "sigmoid"))

rede_neural.summary()

rede_neural.compile(optimizer="Adam", loss="binary_crossentropy", metrics = ["accuracy"])

rede_neural.fit(X_train, y_train, epochs=200)

y_pred = rede_neural.predict(X_test)
y_pred

y_pred = (y_pred >= 0.5)
y_pred

cm = confusion_matrix(y_test, y_pred)
cm

sns.heatmap(cm, annot = True)

print(classification_report(y_test, y_pred))

"""# Salvar Classificador"""

import pickle

with open("variaveis_modelo.pkl", "wb") as f:
  pickle.dump([scaler, onehotencoder, logistic], f)

with open("variaveis_modelo.pkl", "rb") as f:
  min_max, encoder, model = pickle.load(f)

min_max, encoder, model

X_novo = employee_df.iloc[0:1]
X_novo

X_cat_novo = X_novo[["BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus"]]
X_cat_novo

X_cat_novo = encoder.transform(X_cat_novo).toarray()
X_cat_novo

X_cat_novo = pd.DataFrame(X_cat_novo)
X_cat_novo

X_numerical_novo = X_novo[['Age', 'DailyRate', 'DistanceFromHome',	'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement',	'JobLevel',	'JobSatisfaction',	'MonthlyIncome',	'MonthlyRate',	'NumCompaniesWorked',	'OverTime',	'PercentSalaryHike', 'PerformanceRating',	'RelationshipSatisfaction',	'StockOptionLevel',	'TotalWorkingYears'	,'TrainingTimesLastYear'	, 'WorkLifeBalance',	'YearsAtCompany'	,'YearsInCurrentRole', 'YearsSinceLastPromotion',	'YearsWithCurrManager']]
X_numerical_novo

X_all_novo = pd.concat([X_cat_novo, X_numerical_novo], axis = 1)
X_all_novo

X_all_novo.columns = X_all_novo.columns.astype(str)

X_novo = min_max.transform(X_all_novo)
X_novo

model.predict(X_novo)

model.predict_proba(X_novo)

model.classes_